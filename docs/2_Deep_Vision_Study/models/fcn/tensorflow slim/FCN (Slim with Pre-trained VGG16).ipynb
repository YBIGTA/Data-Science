{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fcn_model.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference 1 : https://github.com/shekkizh/FCN.tensorflow/blob/master/FCN.py\n",
    "<br>Reference 2 : https://modulabs-biomedical.github.io/FCN\n",
    "<br>Reference 3 : https://stackoverflow.com/questions/38160940/how-to-count-total-number-of-trainable-parameters-in-a-tensorflow-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets as nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# image size\n",
    "\n",
    "height = 224\n",
    "width = 224\n",
    "num_of_channels = 3\n",
    "num_of_classes = 21\n",
    "\n",
    "keep_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = tf.placeholder(tf.float32, [None, height, width, num_of_channels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tensor_info(tensor):\n",
    "    print(tensor.name + \" / shape = \" + str(tensor.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fcn8_with_pretrained_vgg16(image, num_of_classes, keep_prob):\n",
    "    \n",
    "    \"Extracting Layers from Pre-trained VGG16\"\n",
    "    print(\"------------------- Conv Layer -------------------\")\n",
    "    \n",
    "    vgg16 = nets.vgg.vgg_16(image, num_classes = num_of_classes, dropout_keep_prob = keep_prob)\n",
    "    \n",
    "    pool3 = tf.get_default_graph().get_tensor_by_name('vgg_16/pool3/MaxPool:0')\n",
    "    tensor_info(pool3)\n",
    "    \n",
    "    pool4 = tf.get_default_graph().get_tensor_by_name('vgg_16/pool4/MaxPool:0')\n",
    "    tensor_info(pool4)\n",
    "    \n",
    "    pool5 = tf.get_default_graph().get_tensor_by_name('vgg_16/pool5/MaxPool:0')\n",
    "    tensor_info(pool5)\n",
    "    \n",
    "    \n",
    "    \"Feature-level Classificaiton\"\n",
    "    \n",
    "    # output shape = [None, H/32, H/32, 4096]\n",
    "    conv6 = slim.conv2d(pool5, 4096, [7, 7], scope = 'conv6')\n",
    "    conv6 = tf.nn.dropout(conv6, keep_prob = keep_prob)\n",
    "    tensor_info(conv6)\n",
    "    \n",
    "    # output shape = [None, H/32, H/32, 4096]\n",
    "    conv7 = slim.conv2d(conv6, 4096, [1, 1], scope = 'conv7')\n",
    "    conv7 = tf.nn.dropout(conv7, keep_prob = keep_prob)\n",
    "    tensor_info(conv7)\n",
    "    \n",
    "    # output shape = [None, H/32, H/32, num_of_classes]\n",
    "    conv8 = slim.conv2d(conv7, num_of_classes, [1, 1], scope = 'conv8')\n",
    "    tensor_info(conv8)\n",
    "    \n",
    "    \n",
    "    \"Upsampling\"\n",
    "    print(\"------------------- Upsampling -------------------\")\n",
    "    \n",
    "    conv_t1 = slim.conv2d_transpose(conv8, num_outputs = pool4.get_shape()[3], kernel_size = [4, 4], stride = 2)\n",
    "    fuse_1 = tf.add(conv_t1, pool4, name = 'fuse_1')\n",
    "    tensor_info(fuse_1)\n",
    "    \n",
    "    conv_t2 = slim.conv2d_transpose(fuse_1, num_outputs = pool3.get_shape()[3], kernel_size = 4, stride = 2)\n",
    "    fuse_2 = tf.add(conv_t2, pool3, name = 'fuse_2')\n",
    "    tensor_info(fuse_2)\n",
    "    \n",
    "    conv_t3 = slim.conv2d_transpose(fuse_2, num_outputs = num_of_channels, kernel_size = 16, stride = 8)\n",
    "    tensor_info(conv_t3)\n",
    "    \n",
    "    \n",
    "    \"Segmentation\"\n",
    "    print(\"------------------ Segmentation ------------------\")\n",
    "    \n",
    "    annotation_pred = tf.argmax(conv_t3, dimension = num_of_channels, name=\"prediction\")\n",
    "    tensor_info(annotation_pred)\n",
    "    \n",
    "    fcn8 = tf.expand_dims(annotation_pred, dim = num_of_channels)\n",
    "    tensor_info(fcn8)\n",
    "    \n",
    "    return fcn8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- Conv Layer -------------------\n",
      "vgg_16/pool3/MaxPool:0 / shape = (?, 28, 28, 256)\n",
      "vgg_16/pool4/MaxPool:0 / shape = (?, 14, 14, 512)\n",
      "vgg_16/pool5/MaxPool:0 / shape = (?, 7, 7, 512)\n",
      "dropout/mul:0 / shape = (?, 7, 7, 4096)\n",
      "dropout_1/mul:0 / shape = (?, 7, 7, 4096)\n",
      "conv8/Relu:0 / shape = (?, 7, 7, 21)\n",
      "------------------- Upsampling -------------------\n",
      "fuse_1:0 / shape = (?, 14, 14, 512)\n",
      "fuse_2:0 / shape = (?, 28, 28, 256)\n",
      "Conv2d_transpose_2/Relu:0 / shape = (?, 224, 224, 3)\n",
      "------------------ Segmentation ------------------\n",
      "prediction:0 / shape = (?, 224, 224)\n",
      "ExpandDims:0 / shape = (?, 224, 224, 1)\n"
     ]
    }
   ],
   "source": [
    "fcn8_with_pretrained_vgg16 = fcn8_with_pretrained_vgg16(image, num_of_classes, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Weights : 256,445,037\n"
     ]
    }
   ],
   "source": [
    "total_parameters = np.sum([np.prod(var.get_shape().as_list()) for var in tf.trainable_variables()])\n",
    "print(\"Number of Weights : \" + format(total_parameters, ','))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
