{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1_Multi-variable linear regression\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  7764.883 \n",
      "Prediction:\n",
      " [78.01142  87.300255 89.04278  99.63412  62.97303 ]\n",
      "100 Cost:  20.63519 \n",
      "Prediction:\n",
      " [155.93022 181.25572 181.46185 200.28508 134.70543]\n",
      "200 Cost:  19.70903 \n",
      "Prediction:\n",
      " [155.7746  181.36328 181.41527 200.24278 134.85384]\n",
      "300 Cost:  18.830942 \n",
      "Prediction:\n",
      " [155.62321 181.46793 181.37    200.20145 134.9984 ]\n",
      "400 Cost:  17.998394 \n",
      "Prediction:\n",
      " [155.47597 181.56973 181.32597 200.16106 135.13922]\n",
      "500 Cost:  17.209047 \n",
      "Prediction:\n",
      " [155.33278 181.6688  181.2832  200.12158 135.2764 ]\n",
      "600 Cost:  16.460674 \n",
      "Prediction:\n",
      " [155.1935  181.76512 181.24162 200.083   135.41   ]\n",
      "700 Cost:  15.750961 \n",
      "Prediction:\n",
      " [155.05801 181.85884 181.20119 200.04526 135.54016]\n",
      "800 Cost:  15.078003 \n",
      "Prediction:\n",
      " [154.92627 181.95001 181.16193 200.00838 135.66696]\n",
      "900 Cost:  14.439835 \n",
      "Prediction:\n",
      " [154.79816 182.03873 181.12376 199.97235 135.7905 ]\n",
      "1000 Cost:  13.834521 \n",
      "Prediction:\n",
      " [154.67352 182.125   181.08665 199.93706 135.91083]\n",
      "1100 Cost:  13.260526 \n",
      "Prediction:\n",
      " [154.55234 182.20891 181.0506  199.90259 136.02806]\n",
      "1200 Cost:  12.716049 \n",
      "Prediction:\n",
      " [154.4345  182.29057 181.01558 199.86887 136.14227]\n",
      "1300 Cost:  12.199556 \n",
      "Prediction:\n",
      " [154.31989 182.37    180.98154 199.83588 136.25356]\n",
      "1400 Cost:  11.709608 \n",
      "Prediction:\n",
      " [154.20844 182.44724 180.94846 199.80359 136.36197]\n",
      "1500 Cost:  11.244841 \n",
      "Prediction:\n",
      " [154.10004 182.52235 180.91632 199.77202 136.46759]\n",
      "1600 Cost:  10.803865 \n",
      "Prediction:\n",
      " [153.99466 182.59546 180.8851  199.74113 136.57051]\n",
      "1700 Cost:  10.385443 \n",
      "Prediction:\n",
      " [153.89218 182.66655 180.85477 199.71092 136.6708 ]\n",
      "1800 Cost:  9.9884 \n",
      "Prediction:\n",
      " [153.79253 182.7357  180.8253  199.68135 136.76852]\n",
      "1900 Cost:  9.61159 \n",
      "Prediction:\n",
      " [153.69566 182.80298 180.79668 199.6524  136.86375]\n",
      "2000 Cost:  9.254023 \n",
      "Prediction:\n",
      " [153.60144 182.86838 180.76889 199.62407 136.95653]\n"
     ]
    }
   ],
   "source": [
    "x1_data = [73., 93., 89., 96., 73]\n",
    "x2_data = [80., 88., 91., 98., 66.]\n",
    "x3_data = [75., 93., 90., 100., 70.]\n",
    "y_data = [152., 185., 180., 196., 142.]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1]), name='weight1')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name='weight2')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name='weight3')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "hypothesis = x1 * w1 + x2 * w2 + x3 * w3 + b\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "# Minimize. Need a very small learning rate for this data set\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                  feed_dict={x1: x1_data, x2:x2_data, x3:x3_data, Y:y_data})\n",
    "    if step % 100 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Matrix\n",
    "-------------\n",
    "- 각 케이스별로 [] 안에 input값을 입력해준다.\n",
    "- X의 shape을 [None, 변수의 개수]로 지정해준다.\n",
    "- 그에 알맞게 Y의 shape은 [None, 1], W는 [변수의 개수, 1]이 된다.\n",
    "- X matrix의 행에 원하는 만큼 케이스를 추가해줄 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  100864.64 \n",
      "Prediction:\n",
      " [[-126.599075]\n",
      " [-156.69109 ]\n",
      " [-152.10484 ]\n",
      " [-165.39326 ]\n",
      " [-120.78177 ]]\n",
      "100 Cost:  8.670284 \n",
      "Prediction:\n",
      " [[155.0768 ]\n",
      " [182.07227]\n",
      " [181.57552]\n",
      " [197.98555]\n",
      " [137.65392]]\n",
      "200 Cost:  8.24 \n",
      "Prediction:\n",
      " [[154.96872]\n",
      " [182.14665]\n",
      " [181.54277]\n",
      " [197.95885]\n",
      " [137.75407]]\n",
      "300 Cost:  7.832338 \n",
      "Prediction:\n",
      " [[154.86359]\n",
      " [182.21906]\n",
      " [181.51096]\n",
      " [197.93285]\n",
      " [137.85162]]\n",
      "400 Cost:  7.4460754 \n",
      "Prediction:\n",
      " [[154.76126]\n",
      " [182.28949]\n",
      " [181.47998]\n",
      " [197.90746]\n",
      " [137.94658]]\n",
      "500 Cost:  7.0801344 \n",
      "Prediction:\n",
      " [[154.66171]\n",
      " [182.35802]\n",
      " [181.44986]\n",
      " [197.88269]\n",
      " [138.03903]]\n",
      "600 Cost:  6.733345 \n",
      "Prediction:\n",
      " [[154.56488]\n",
      " [182.42473]\n",
      " [181.42058]\n",
      " [197.85852]\n",
      " [138.12909]]\n",
      "700 Cost:  6.404828 \n",
      "Prediction:\n",
      " [[154.47063]\n",
      " [182.4896 ]\n",
      " [181.39206]\n",
      " [197.83493]\n",
      " [138.21672]]\n",
      "800 Cost:  6.0935187 \n",
      "Prediction:\n",
      " [[154.37898]\n",
      " [182.55275]\n",
      " [181.36436]\n",
      " [197.81194]\n",
      " [138.30211]]\n",
      "900 Cost:  5.7985353 \n",
      "Prediction:\n",
      " [[154.28978]\n",
      " [182.6142 ]\n",
      " [181.3374 ]\n",
      " [197.78949]\n",
      " [138.38522]]\n",
      "1000 Cost:  5.5190454 \n",
      "Prediction:\n",
      " [[154.20302]\n",
      " [182.67398]\n",
      " [181.31122]\n",
      " [197.76761]\n",
      " [138.46619]]\n",
      "1100 Cost:  5.254204 \n",
      "Prediction:\n",
      " [[154.1186 ]\n",
      " [182.73216]\n",
      " [181.28572]\n",
      " [197.74623]\n",
      " [138.545  ]]\n",
      "1200 Cost:  5.003279 \n",
      "Prediction:\n",
      " [[154.03647]\n",
      " [182.78874]\n",
      " [181.26091]\n",
      " [197.72536]\n",
      " [138.62172]]\n",
      "1300 Cost:  4.765464 \n",
      "Prediction:\n",
      " [[153.95657]\n",
      " [182.84381]\n",
      " [181.23682]\n",
      " [197.70499]\n",
      " [138.69647]]\n",
      "1400 Cost:  4.5401244 \n",
      "Prediction:\n",
      " [[153.87883]\n",
      " [182.89738]\n",
      " [181.21336]\n",
      " [197.6851 ]\n",
      " [138.76924]]\n",
      "1500 Cost:  4.326578 \n",
      "Prediction:\n",
      " [[153.8032 ]\n",
      " [182.94954]\n",
      " [181.19057]\n",
      " [197.66573]\n",
      " [138.84012]]\n",
      "1600 Cost:  4.1242304 \n",
      "Prediction:\n",
      " [[153.72964]\n",
      " [183.00026]\n",
      " [181.1684 ]\n",
      " [197.64679]\n",
      " [138.90913]]\n",
      "1700 Cost:  3.9324577 \n",
      "Prediction:\n",
      " [[153.65808]\n",
      " [183.04962]\n",
      " [181.14685]\n",
      " [197.6283 ]\n",
      " [138.97635]]\n",
      "1800 Cost:  3.7507262 \n",
      "Prediction:\n",
      " [[153.58846]\n",
      " [183.09763]\n",
      " [181.12587]\n",
      " [197.61026]\n",
      " [139.04181]]\n",
      "1900 Cost:  3.5784965 \n",
      "Prediction:\n",
      " [[153.52074]\n",
      " [183.14435]\n",
      " [181.1055 ]\n",
      " [197.59264]\n",
      " [139.10556]]\n",
      "2000 Cost:  3.4152603 \n",
      "Prediction:\n",
      " [[153.45485]\n",
      " [183.18982]\n",
      " [181.08568]\n",
      " [197.57542]\n",
      " [139.16763]]\n"
     ]
    }
   ],
   "source": [
    "x_data = [[73., 80., 75], [93., 88., 93.], [89., 91., 90.], [96., 98., 100.], [73., 66., 70.]]\n",
    "y_data = [[152.], [185.], [180.], [196.], [142.]]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "# hypothesis = X * W + b\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "# Minimize. Need a very small learning rate for this data set\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                  feed_dict={X:x_data, Y:y_data})\n",
    "    if step % 100 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2_Loading data from file\n",
    "-------------\n",
    "- numpy를 이용하여 외부 파일의 데이터를 읽어온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 3) [[ 73.  80.  75.]\n",
      " [ 93.  88.  93.]\n",
      " [ 89.  91.  90.]\n",
      " [ 96.  98. 100.]\n",
      " [ 73.  66.  70.]\n",
      " [ 53.  46.  55.]\n",
      " [ 69.  74.  77.]\n",
      " [ 47.  56.  60.]\n",
      " [ 87.  79.  90.]\n",
      " [ 79.  70.  88.]\n",
      " [ 69.  70.  73.]\n",
      " [ 70.  65.  74.]\n",
      " [ 93.  95.  91.]\n",
      " [ 79.  80.  73.]\n",
      " [ 70.  73.  78.]\n",
      " [ 93.  89.  96.]\n",
      " [ 78.  75.  68.]\n",
      " [ 81.  90.  93.]\n",
      " [ 88.  92.  86.]\n",
      " [ 78.  83.  77.]\n",
      " [ 82.  86.  90.]\n",
      " [ 86.  82.  89.]\n",
      " [ 78.  83.  85.]\n",
      " [ 76.  83.  71.]\n",
      " [ 96.  93.  95.]] 25\n",
      "(25, 1) [[152.]\n",
      " [185.]\n",
      " [180.]\n",
      " [196.]\n",
      " [142.]\n",
      " [101.]\n",
      " [149.]\n",
      " [115.]\n",
      " [175.]\n",
      " [164.]\n",
      " [141.]\n",
      " [141.]\n",
      " [184.]\n",
      " [152.]\n",
      " [148.]\n",
      " [192.]\n",
      " [147.]\n",
      " [183.]\n",
      " [177.]\n",
      " [159.]\n",
      " [177.]\n",
      " [175.]\n",
      " [175.]\n",
      " [149.]\n",
      " [192.]]\n"
     ]
    }
   ],
   "source": [
    "xy = np.loadtxt('C:/Users/rinseo/Documents/GitHub/DeepLearningZeroToAll/data-01-test-score.csv',\n",
    "               delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1] # 마지막 열을 제외하고 모든 행\n",
    "y_data = xy[:, [-1]] # 마지막 열만을 모든 행에서\n",
    "\n",
    "# y_data = xy[:, -1]\n",
    "# 위 경우 사례별로 일일이 저장되지 않는 문제가 있음\n",
    "\n",
    "# Make sure the shape and data are OK\n",
    "print(x_data.shape, x_data, len(x_data))\n",
    "print(y_data.shape, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  1072.8235 \n",
      "Prediction:\n",
      " [[123.412506]\n",
      " [146.06294 ]\n",
      " [144.85948 ]\n",
      " [159.73798 ]\n",
      " [109.3475  ]\n",
      " [ 83.6867  ]\n",
      " [123.36545 ]\n",
      " [ 96.76279 ]\n",
      " [138.54324 ]\n",
      " [132.68376 ]\n",
      " [116.1544  ]\n",
      " [114.380356]\n",
      " [147.5086  ]\n",
      " [119.673416]\n",
      " [123.83638 ]\n",
      " [150.34874 ]\n",
      " [110.86894 ]\n",
      " [149.69754 ]\n",
      " [140.664   ]\n",
      " [126.53256 ]\n",
      " [143.51866 ]\n",
      " [139.1948  ]\n",
      " [136.46472 ]\n",
      " [119.50214 ]\n",
      " [150.72417 ]]\n",
      "1000 Cost:  8.36437 \n",
      "Prediction:\n",
      " [[153.88788]\n",
      " [183.24199]\n",
      " [181.2246 ]\n",
      " [199.1547 ]\n",
      " [137.99368]\n",
      " [104.57988]\n",
      " [152.43561]\n",
      " [117.69   ]\n",
      " [173.18744]\n",
      " [164.4062 ]\n",
      " [144.51894]\n",
      " [142.5189 ]\n",
      " [185.28197]\n",
      " [151.38065]\n",
      " [153.10152]\n",
      " [187.84654]\n",
      " [141.46509]\n",
      " [184.33865]\n",
      " [176.6206 ]\n",
      " [158.61116]\n",
      " [177.75436]\n",
      " [173.8545 ]\n",
      " [169.11269]\n",
      " [150.69563]\n",
      " [189.25885]]\n",
      "2000 Cost:  7.5079103 \n",
      "Prediction:\n",
      " [[153.72719]\n",
      " [183.51012]\n",
      " [181.26253]\n",
      " [199.05962]\n",
      " [138.4249 ]\n",
      " [104.74005]\n",
      " [152.03113]\n",
      " [116.91079]\n",
      " [173.37773]\n",
      " [164.32132]\n",
      " [144.4069 ]\n",
      " [142.55931]\n",
      " [185.47006]\n",
      " [151.76398]\n",
      " [152.74887]\n",
      " [187.9456 ]\n",
      " [142.13934]\n",
      " [183.66039]\n",
      " [176.75063]\n",
      " [158.65248]\n",
      " [177.39525]\n",
      " [173.94266]\n",
      " [168.77019]\n",
      " [150.87544]\n",
      " [189.52934]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# tf.set_random_seed(777)\n",
    "# 아래 경우 W가 random state이기 때문에 다른 값이 나옴\n",
    "\n",
    "xy = np.loadtxt('C:/Users/rinseo/Documents/GitHub/DeepLearningZeroToAll/data-01-test-score.csv',\n",
    "               delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                  feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 1000 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your score will be  [[182.74513]]\n",
      "Other scores will be  [[190.34984]\n",
      " [174.48207]]\n"
     ]
    }
   ],
   "source": [
    "# Ask my score\n",
    "print(\"Your score will be \", sess.run(hypothesis,\n",
    "                                     feed_dict={X: [[100, 70, 101]]}))\n",
    "print(\"Other scores will be \", sess.run(hypothesis,\n",
    "                                     feed_dict={X: [[60, 70, 110], [90, 100, 80]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing, Slicing, Iterating\n",
    "-------------\n",
    "- Arrays can be indexed, sliced, iterated like lists and other sequence types in Python\n",
    "- As with Python lists, slicing in NumPy can be accomplished with colon (:)\n",
    "- Colon instances (:) can be replaced with dots (...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3]\n",
      "5\n",
      "[9 9 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "print(a[1:3])\n",
    "\n",
    "print(a[-1])\n",
    "\n",
    "a[0:2] = 9\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  6 10]\n",
      "[ 9 10 11 12]\n"
     ]
    }
   ],
   "source": [
    "b = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
    "\n",
    "print(b[:, 1])\n",
    "\n",
    "print(b[-1])\n",
    "# print(b[-1, :])\n",
    "# print(b[-1, ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queue Runners\n",
    "-------------\n",
    "* * *\n",
    "*Step 1. Enqueue filenames*\n",
    "\n",
    "- filename_queue = tf.train.string_input_producer(['file01.csv', 'file02.csv', ...], shuffle=False, name='filename_queue')\n",
    "                                                \n",
    "*Step 2. Dequeue with readers*\n",
    "\n",
    "- reader = tf.TextLineReader()\n",
    "- key, value = reader.read(filename.queue)\n",
    "\n",
    "*Step 3. Make example queue in order*\n",
    "\n",
    "- record_defaults = [[0.], [0.], [0.], [0.]]\n",
    "- xy = tf.decode_csv(value, record_defaults=record_defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-a1871f4cee1b>:3: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From C:\\Users\\rinseo\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\training\\input.py:276: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From C:\\Users\\rinseo\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\training\\input.py:188: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From C:\\Users\\rinseo\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\training\\input.py:197: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\rinseo\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\training\\input.py:197: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-9-a1871f4cee1b>:5: TextLineReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.\n",
      "WARNING:tensorflow:From <ipython-input-9-a1871f4cee1b>:15: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "filename_queue = tf.train.string_input_producer(['C:/Users/rinseo/Documents/GitHub/DeepLearningZeroToAll/data-01-test-score.csv'],\n",
    "                                               shuffle=False, name='filename_queue')\n",
    "\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "# Default values, in case of empty columns.\n",
    "# Also specifies the type of the decoded result.\n",
    "record_defaults = [[0.], [0.], [0.], [0.]]\n",
    "xy = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "\n",
    "# collect batches of csv in\n",
    "train_x_batch, train_y_batch = tf.train.batch([xy[0:-1], xy[-1:]],\n",
    "                                              batch_size=10)\n",
    "# train_y_batch를 xy[-1]]로 설정해줄 경우 오류 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 3) [[ 73.  80.  75.]\n",
      " [ 93.  88.  93.]\n",
      " [ 89.  91.  90.]\n",
      " [ 96.  98. 100.]\n",
      " [ 73.  66.  70.]\n",
      " [ 53.  46.  55.]\n",
      " [ 69.  74.  77.]\n",
      " [ 47.  56.  60.]\n",
      " [ 87.  79.  90.]\n",
      " [ 79.  70.  88.]\n",
      " [ 69.  70.  73.]\n",
      " [ 70.  65.  74.]\n",
      " [ 93.  95.  91.]\n",
      " [ 79.  80.  73.]\n",
      " [ 70.  73.  78.]\n",
      " [ 93.  89.  96.]\n",
      " [ 78.  75.  68.]\n",
      " [ 81.  90.  93.]\n",
      " [ 88.  92.  86.]\n",
      " [ 78.  83.  77.]\n",
      " [ 82.  86.  90.]\n",
      " [ 86.  82.  89.]\n",
      " [ 78.  83.  85.]\n",
      " [ 76.  83.  71.]\n",
      " [ 96.  93.  95.]] 25\n",
      "(25, 1) [[152.]\n",
      " [185.]\n",
      " [180.]\n",
      " [196.]\n",
      " [142.]\n",
      " [101.]\n",
      " [149.]\n",
      " [115.]\n",
      " [175.]\n",
      " [164.]\n",
      " [141.]\n",
      " [141.]\n",
      " [184.]\n",
      " [152.]\n",
      " [148.]\n",
      " [192.]\n",
      " [147.]\n",
      " [183.]\n",
      " [177.]\n",
      " [159.]\n",
      " [177.]\n",
      " [175.]\n",
      " [175.]\n",
      " [149.]\n",
      " [192.]]\n"
     ]
    }
   ],
   "source": [
    "print(x_data.shape, x_data, len(x_data))\n",
    "print(y_data.shape, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-52c378a8b89c>:16: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "0 Cost:  26795.88 \n",
      "Prediction:\n",
      " [[ -8.967588 ]\n",
      " [  0.8523198]\n",
      " [ -5.00749  ]\n",
      " [ -8.330496 ]\n",
      " [  6.1142826]\n",
      " [  1.8187122]\n",
      " [-13.478403 ]\n",
      " [-20.553022 ]\n",
      " [  0.1826573]\n",
      " [ -4.885565 ]]\n",
      "1000 Cost:  50.198383 \n",
      "Prediction:\n",
      " [[150.3128 ]\n",
      " [190.60355]\n",
      " [182.73503]\n",
      " [197.26566]\n",
      " [149.47818]\n",
      " [109.06308]\n",
      " [142.57411]\n",
      " [ 98.19952]\n",
      " [178.50877]\n",
      " [162.63657]]\n",
      "2000 Cost:  31.95693 \n",
      "Prediction:\n",
      " [[150.74379 ]\n",
      " [189.5008  ]\n",
      " [182.41866 ]\n",
      " [197.71318 ]\n",
      " [147.5807  ]\n",
      " [108.697754]\n",
      " [144.543   ]\n",
      " [101.99116 ]\n",
      " [178.07056 ]\n",
      " [163.83752 ]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Start populating the filename queue.\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "for step in range(2001):\n",
    "    x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                  feed_dict={X: x_batch, Y: y_batch})\n",
    "    if step % 1000 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: shuffle_batch\n",
    "-------------\n",
    "- min_after_deque defines how big a buffer we will randomly sample from\n",
    "- bigger means better shuffling but slower start up and more memory used.\n",
    "\n",
    "- capacity must be larger than min_after_deque\n",
    "- the amount larger determines the maximum we will prefetch.\n",
    "\n",
    "- Recommendation:\n",
    "- min_after_deque + (num_threads + a small safety margin) * batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-341bd458b84d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmin_after_deque\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcapacity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_after_deque\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m example_batch, label_batch = tf.train.shuffle_batch([example, label], batch_size=batch_size,\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "min_after_deque = 10000\n",
    "\n",
    "capacity = min_after_deque + 3 * batch_size\n",
    "\n",
    "example_batch, label_batch = tf.train.shuffle_batch([example, label], batch_size=batch_size,\n",
    "                                                    capacity=capacity, min_after_deque=min_after_deque)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
